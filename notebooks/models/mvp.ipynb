{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(target, min=-1, max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_map = self.conv(x)\n",
    "        attention_map = self.sigmoid(attention_map)  # Normalize to range [0, 1]\n",
    "        return x * attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationWithAttention(nn.Module):\n",
    "    def __init__(self, backbone_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=True)\n",
    "        in_features = (\n",
    "            self.backbone.classifier.in_features\n",
    "        )  # Adapt based on the backbone\n",
    "\n",
    "        # Remove the original classification head of the backbone\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        self.attention = SpatialAttentionModule(in_features)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.head = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf_efficientnetv2_b0.in1k',\n",
       " 'tf_efficientnetv2_b1.in1k',\n",
       " 'tf_efficientnetv2_b2.in1k',\n",
       " 'tf_efficientnetv2_b3.in1k',\n",
       " 'tf_efficientnetv2_b3.in21k',\n",
       " 'tf_efficientnetv2_b3.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_l.in1k',\n",
       " 'tf_efficientnetv2_l.in21k',\n",
       " 'tf_efficientnetv2_l.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_m.in1k',\n",
       " 'tf_efficientnetv2_m.in21k',\n",
       " 'tf_efficientnetv2_m.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_s.in1k',\n",
       " 'tf_efficientnetv2_s.in21k',\n",
       " 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_xl.in21k',\n",
       " 'tf_efficientnetv2_xl.in21k_ft_in1k']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"tf_efficientnetv2*\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet_b0.ra_in1k',\n",
       " 'efficientnet_b1.ft_in1k',\n",
       " 'efficientnet_b1_pruned.in1k',\n",
       " 'efficientnet_b2.ra_in1k',\n",
       " 'efficientnet_b2_pruned.in1k',\n",
       " 'efficientnet_b3.ra2_in1k',\n",
       " 'efficientnet_b3_pruned.in1k',\n",
       " 'efficientnet_b4.ra2_in1k',\n",
       " 'efficientnet_b5.sw_in12k',\n",
       " 'efficientnet_b5.sw_in12k_ft_in1k',\n",
       " 'efficientnet_el.ra_in1k',\n",
       " 'efficientnet_el_pruned.in1k',\n",
       " 'efficientnet_em.ra2_in1k',\n",
       " 'efficientnet_es.ra_in1k',\n",
       " 'efficientnet_es_pruned.in1k',\n",
       " 'efficientnet_lite0.ra_in1k',\n",
       " 'efficientnetv2_rw_m.agc_in1k',\n",
       " 'efficientnetv2_rw_s.ra2_in1k',\n",
       " 'efficientnetv2_rw_t.ra2_in1k']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"efficientnet*\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"efficientnet_b0\", pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
