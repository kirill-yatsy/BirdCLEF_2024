{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lex/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import onnxruntime as nxrun\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torch\n",
    "import librosa\n",
    "import timm\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    sample_rate = 32000\n",
    "    output_window_duration = 5\n",
    "    input_window_duration = 5\n",
    "    batch_size = 2\n",
    "    image_width = 157\n",
    "    audio_len = sample_rate * input_window_duration\n",
    "    hop_length = audio_len // (image_width - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data/birdclef-2024\"\n",
    "MODEL_PATH = \"../production/dpn68b/v1.onnx\"\n",
    "# MODEL_PATH = \"../model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = glob(f\"{BASE_PATH}/test_soundscapes/*ogg\")\n",
    "# During commit use `unlabeled` data as there is no `test` data.\n",
    "# During submission `test` data will automatically be populated.\n",
    "if len(test_paths) == 0:\n",
    "    test_paths = glob(f\"{BASE_PATH}/unlabeled_soundscapes/*ogg\")[:40]\n",
    "test_df = pd.DataFrame(test_paths, columns=[\"filepath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = nxrun.InferenceSession(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(MODEL_PATH)\n",
    "\n",
    "# model = timm.create_model(\n",
    "#     \"tf_efficientnet_b0_ns\",\n",
    "#     pretrained=True,\n",
    "#     num_classes=182,\n",
    "#     global_pool=\"avg\",\n",
    "#     in_chans=3,\n",
    "# )\n",
    "\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "1. Create data loader\n",
    "2. We need to classify track every 5 seconds, but model trained on 10 seconds windows. \n",
    " - if track is less than 10 seconds, we will duplicate it to 10 seconds\n",
    " - if track is more than 10 seconds, we will split it to 10 seconds windows\n",
    " - we pass 10 seconds windows\n",
    " - new windows position is after 5 seconds from start of previous window.\n",
    " - last window will be 5 seconds long, we will duplicate it to 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mel_spectrogram(\n",
    "    waveform, sample_rate, n_mels, n_fft, hop_length, f_min, f_max, top_db\n",
    "):\n",
    "    mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        f_min=f_min,\n",
    "        f_max=f_max,\n",
    "    )\n",
    "    amplitude_db_transform = torchaudio.transforms.AmplitudeToDB(top_db=top_db)\n",
    "\n",
    "    mel_spectrogram = mel_spectrogram_transform(waveform)\n",
    "    mel_spectrogram_db = amplitude_db_transform(mel_spectrogram)\n",
    "\n",
    "    return mel_spectrogram_db\n",
    "\n",
    "\n",
    "def generate_mfcc(\n",
    "    waveform, sample_rate, n_mfcc, n_mels, n_fft, hop_length, f_min, f_max\n",
    "):\n",
    "    mfcc_transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=n_mfcc,\n",
    "        melkwargs={\n",
    "            \"n_mels\": n_mels,\n",
    "            \"n_fft\": n_fft,\n",
    "            \"hop_length\": hop_length,\n",
    "            \"f_min\": f_min,\n",
    "            \"f_max\": f_max,\n",
    "        },\n",
    "    )\n",
    "    mfcc = mfcc_transform(waveform)\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def generate_chroma_feature(waveform, sr, n_fft, hop_length, n_chroma, epsilon=1e-6):\n",
    "    try:\n",
    "        stft = torch.stft(\n",
    "            waveform,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            return_complex=True,\n",
    "            win_length=n_fft,\n",
    "            # window=torch.hann_window(n_fft),\n",
    "        )\n",
    "        magnitude = stft.abs() + epsilon  # Adding epsilon to avoid log(0) issues\n",
    "        chroma_filter = librosa.filters.chroma(sr=sr, n_fft=n_fft, n_chroma=n_chroma)\n",
    "        chroma_filter = torch.tensor(chroma_filter, dtype=torch.float32)\n",
    "        chroma = torch.matmul(chroma_filter, magnitude.squeeze(0))\n",
    "        chroma = chroma / torch.max(chroma) + epsilon\n",
    "        return chroma\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # return torch.zeros((n_chroma, 1))\n",
    "\n",
    "\n",
    "class MonoToThreeChannel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate,\n",
    "        n_mels,\n",
    "        n_fft,\n",
    "        hop_length,\n",
    "        f_min,\n",
    "        f_max,\n",
    "        top_db,\n",
    "        n_mfcc,\n",
    "        n_chroma,\n",
    "    ):\n",
    "        super(MonoToThreeChannel, self).__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.top_db = top_db\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_chroma = n_chroma\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        # mel_time = time.time()\n",
    "        # Generate Mel Spectrogram\n",
    "        mel_spectrogram_db = generate_mel_spectrogram(\n",
    "            waveform,\n",
    "            self.sample_rate,\n",
    "            self.n_mels,\n",
    "            self.n_fft,\n",
    "            self.hop_length,\n",
    "            self.f_min,\n",
    "            self.f_max,\n",
    "            self.top_db,\n",
    "        )\n",
    "        # print(f\"Mel Time: {time.time() - mel_time}\")\n",
    "\n",
    "        # mmc_time = time.time()\n",
    "        # Generate MFCC\n",
    "        mfcc = generate_mfcc(\n",
    "            waveform,\n",
    "            self.sample_rate,\n",
    "            self.n_mfcc,\n",
    "            self.n_mels,\n",
    "            self.n_fft,\n",
    "            self.hop_length,\n",
    "            self.f_min,\n",
    "            self.f_max,\n",
    "        )\n",
    "        # Resize MFCC to match Mel Spectrogram dimensions\n",
    "        mfcc_resized = torch.nn.functional.interpolate(\n",
    "            mfcc.unsqueeze(0), size=mel_spectrogram_db.shape[1:], mode=\"bilinear\"\n",
    "        ).squeeze(0)\n",
    "        # print(f\"MMC Time: {time.time() - mmc_time}\")\n",
    "\n",
    "        # chroma_time = time.time()\n",
    "        # Generate Chroma Features\n",
    "        chroma = generate_chroma_feature(\n",
    "            waveform,\n",
    "            sr=self.sample_rate,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            n_chroma=self.n_chroma,\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        # Resize Chroma to match Mel Spectrogram dimensions\n",
    "        chroma_resized = torch.nn.functional.interpolate(\n",
    "            chroma.unsqueeze(0), size=mel_spectrogram_db.shape[1:], mode=\"bilinear\"\n",
    "        ).squeeze(0)\n",
    "        # print(f\"Chroma Time: {time.time() - chroma_time}\")\n",
    "\n",
    "        # stack_time = time.time()\n",
    "        # Stack to create a 3-channel image\n",
    "        final_output = torch.stack(\n",
    "            [mel_spectrogram_db, mfcc_resized, chroma_resized], dim=0\n",
    "        ).squeeze(1)\n",
    "        # print(f\"Stack Time: {time.time() - stack_time}\")\n",
    "        return final_output\n",
    "\n",
    "\n",
    "class NormalizeData(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormalizeData, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        min_val = torch.min(x)\n",
    "        max_val = torch.max(x)\n",
    "        if max_val - min_val == 0:\n",
    "            return x\n",
    "        return (x - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        waveform, sample_rate = torchaudio.load(path)\n",
    "        waveform = self.standardize_waveform(waveform, sample_rate)\n",
    "        self.frames = self.get_frames(waveform)\n",
    "        # self.frames = self.to_model_input(self.frames)\n",
    "\n",
    "    def get_frames(self, waveform):\n",
    "        predict_frame_size = CFG.sample_rate * CFG.output_window_duration\n",
    "        model_frame_size = CFG.sample_rate * CFG.input_window_duration\n",
    "        waveform = torch.cat(\n",
    "            [\n",
    "                waveform,\n",
    "                waveform[:, -1 * predict_frame_size :],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        waveform_with_padding = torch.nn.functional.pad(\n",
    "            waveform, (0, predict_frame_size - waveform.shape[1] % predict_frame_size)\n",
    "        )\n",
    "\n",
    "        windows = []\n",
    "        for i in range(\n",
    "            0,\n",
    "            waveform_with_padding.shape[1] - predict_frame_size,\n",
    "            predict_frame_size,\n",
    "        ):\n",
    "            window = waveform_with_padding[\n",
    "                :, i : i + CFG.sample_rate * CFG.input_window_duration\n",
    "            ]\n",
    "            window = self.to_model_input(window)\n",
    "            windows.append(window)\n",
    "\n",
    "        return torch.stack(windows)\n",
    "\n",
    "    def to_model_input(self, frames):\n",
    "        preparedWawe = torch.nn.Sequential(\n",
    "            *[\n",
    "                MonoToThreeChannel(\n",
    "                    sample_rate=32000,\n",
    "                    n_mels=128,\n",
    "                    n_fft=2048,\n",
    "                    hop_length=CFG.hop_length,\n",
    "                    top_db=80,\n",
    "                    f_min=0,\n",
    "                    f_max=16000,\n",
    "                    n_mfcc=20,\n",
    "                    n_chroma=12,\n",
    "                ),\n",
    "                NormalizeData(),\n",
    "            ]\n",
    "        )\n",
    "        return preparedWawe(frames)\n",
    "\n",
    "    def standardize_waveform(\n",
    "        self, waveform: torch.Tensor, sample_rate: int\n",
    "    ) -> torch.Tensor:\n",
    "        if len(waveform) > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        if sample_rate != CFG.sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(\n",
    "                sample_rate, CFG.sample_rate, dtype=waveform.dtype\n",
    "            )(waveform)\n",
    "\n",
    "        return waveform\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.dataloader:\n",
    "            yield data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderV2:\n",
    "    preparedWawe = torch.nn.Sequential(\n",
    "        *[\n",
    "            MonoToThreeChannel(\n",
    "                sample_rate=32000,\n",
    "                n_mels=128,\n",
    "                n_fft=2048,\n",
    "                hop_length=CFG.hop_length,\n",
    "                top_db=80,\n",
    "                f_min=0,\n",
    "                f_max=16000,\n",
    "                n_mfcc=20,\n",
    "                n_chroma=12,\n",
    "            ),\n",
    "            NormalizeData(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def get_frames(self, waveform):\n",
    "        predict_frame_size = CFG.sample_rate * CFG.output_window_duration\n",
    "        frames_count = waveform.shape[1] // predict_frame_size\n",
    "\n",
    "        waveform = torch.cat(\n",
    "            [\n",
    "                waveform,\n",
    "                waveform[:, -1 * predict_frame_size :],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        waveform_with_padding = torch.nn.functional.pad(\n",
    "            waveform, (0, predict_frame_size - waveform.shape[1] % predict_frame_size)\n",
    "        )\n",
    "\n",
    "        windows = []\n",
    "        for i in range(\n",
    "            0,\n",
    "            frames_count,\n",
    "        ):\n",
    "            window = waveform_with_padding[\n",
    "                :, i : i + CFG.sample_rate * CFG.input_window_duration\n",
    "            ]\n",
    "            window = self.preparedWawe(window)\n",
    "            windows.append(window)\n",
    "\n",
    "        return torch.stack(windows)\n",
    "\n",
    "    def forward(self, path):\n",
    "        self.path = path\n",
    "        load_time = time.time()\n",
    "        waveform, sample_rate = torchaudio.load(path)\n",
    "        load_time = time.time() - load_time\n",
    "\n",
    "        standardize_time = time.time()\n",
    "        waveform = self.standardize_waveform(waveform, sample_rate)\n",
    "        standardize_time = time.time() - standardize_time\n",
    "\n",
    "        get_frames_time = time.time()\n",
    "        frames = self.get_frames(waveform)\n",
    "        get_frames_time = time.time() - get_frames_time\n",
    "\n",
    "        # print(f\"Load Time: {load_time}\")\n",
    "        # print(f\"Standardize Time: {standardize_time}\")\n",
    "        # print(f\"Get Frames Time: {get_frames_time}\")\n",
    "        return frames\n",
    "\n",
    "    def standardize_waveform(\n",
    "        self, waveform: torch.Tensor, sample_rate: int\n",
    "    ) -> torch.Tensor:\n",
    "        if len(waveform) > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        if sample_rate != CFG.sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(\n",
    "                sample_rate, CFG.sample_rate, dtype=waveform.dtype\n",
    "            )(waveform)\n",
    "\n",
    "        return waveform\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.dataloader:\n",
    "            yield data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lex/miniconda3/lib/python3.11/site-packages/torch/functional.py:665: UserWarning: A window was not provided. A rectangular window will be applied,which is known to cause spectral leakage. Other windows such as torch.hann_window or torch.hamming_window can are recommended to reduce spectral leakage.To suppress this warning and use a rectangular window, explicitly set `window=torch.ones(n_fft, device=<device>)`. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:836.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 3, 128, 157])\n"
     ]
    }
   ],
   "source": [
    "output2 = DataLoader(\"../data/birdclef-2024/unlabeled_soundscapes/460830.ogg\")\n",
    "print(output2.frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 3, 128, 157])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoaderV2()\n",
    "output = loader.forward(\"../data/birdclef-2024/unlabeled_soundscapes/460830.ogg\")\n",
    "\n",
    "print(output.shape)\n",
    "# import cProfile\n",
    "\n",
    "# with cProfile.Profile() as pr:\n",
    "#     DataLoader(\"../data/birdclef-2024/unlabeled_soundscapes/460830.ogg\")\n",
    "#     pr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "\n",
    "# with cProfile.Profile() as pr:\n",
    "#     for i in range(100):\n",
    "#         DataLoader(\"../data/birdclef-2024/unlabeled_soundscapes/460830.ogg\")\n",
    "#     pr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# import time\n",
    "\n",
    "# loader = DataLoaderV2()\n",
    "# with cProfile.Profile() as pr:\n",
    "#     for i in range(1):\n",
    "#         loader.forward(\"../data/birdclef-2024/unlabeled_soundscapes/460830.ogg\")\n",
    "#     pr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/birdclef-2024/unlabeled_soundscapes/13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/birdclef-2024/unlabeled_soundscapes/92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/birdclef-2024/unlabeled_soundscapes/13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/birdclef-2024/unlabeled_soundscapes/19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/birdclef-2024/unlabeled_soundscapes/91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath\n",
       "0  ../data/birdclef-2024/unlabeled_soundscapes/13...\n",
       "1  ../data/birdclef-2024/unlabeled_soundscapes/92...\n",
       "2  ../data/birdclef-2024/unlabeled_soundscapes/13...\n",
       "3  ../data/birdclef-2024/unlabeled_soundscapes/19...\n",
       "4  ../data/birdclef-2024/unlabeled_soundscapes/91..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths = glob(f\"{BASE_PATH}/test_soundscapes/*ogg\")\n",
    "# During commit use `unlabeled` data as there is no `test` data.\n",
    "# During submission `test` data will automatically be populated.\n",
    "if len(test_paths) == 0:\n",
    "    test_paths = glob(f\"{BASE_PATH}/unlabeled_soundscapes/*ogg\")[:50]\n",
    "test_df = pd.DataFrame(test_paths, columns=[\"filepath\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = BirdCLEFDataset(test_df[\"filepath\"].tolist())\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4\n",
    "# )\\\n",
    "\n",
    "loader = DataLoader(test_df[\"filepath\"].loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classMapperDF = pd.read_csv(f\"../data/processed/fine_tune_mapper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(columns=np.concatenate(([\"row_id\"], classMapperDF[\"species\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, asbfly, ashdro1, ashpri1, ashwoo2, asikoe2, asiope1, aspfly1, aspswi1, barfly1, barswa, bcnher, bkcbul1, bkrfla1, bkskit1, bkwsti, bladro1, blaeag1, blakit1, blhori1, blnmon1, blrwar1, bncwoo3, brakit1, brasta1, brcful1, brfowl1, brnhao1, brnshr, brodro1, brwjac1, brwowl1, btbeat1, bwfshr1, categr, chbeat1, cohcuc1, comfla1, comgre, comior1, comkin1, commoo3, commyn, compea, comros, comsan, comtai1, copbar1, crbsun2, cregos1, crfbar1, crseag1, dafbab1, darter2, eaywag1, emedov2, eucdov, eurbla2, eurcoo, forwag1, gargan, gloibi, goflea1, graher1, grbeat1, grecou1, greegr, grefla1, grehor1, grejun2, grenig1, grewar3, grnsan, grnwar1, grtdro1, gryfra, grynig2, grywag, gybpri1, gyhcaf1, heswoo1, hoopoe, houcro1, houspa, inbrob1, indpit1, indrob1, indrol2, indtit1, ingori1, inpher1, insbab1, insowl1, integr, isbduc1, jerbus2, junbab2, junmyn1, junowl1, kenplo1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 183 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test :   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tqdm.std.tqdm at 0x775144d48490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm(iter(test_df), desc=\"test \", total=len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 50/50 [00:22<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:22.384296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "loader = DataLoaderV2()\n",
    "start_time = datetime.now()\n",
    "new_rows = []\n",
    "with torch.no_grad():\n",
    "    # for path in test_df[\"filepath\"]:\n",
    "    for idx, path in enumerate(\n",
    "        tqdm(iter(test_df[\"filepath\"]), desc=\"test\", total=len(test_df[\"filepath\"]))\n",
    "    ):\n",
    "        base_row_id = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        # data_loader = DataLoader(path)\n",
    "        frames = loader.forward(path)\n",
    "        # start_p_time = datetime.now()\n",
    "\n",
    "        output_array = onnx_model.run(None, {\"input\": frames.numpy()})[0]\n",
    "        # output_array = model(frames)\n",
    "        # apply softmax using pytorch\n",
    "        # output_array = torch.nn.functional.softmax(output_array, dim=1)\n",
    "        output_array = (\n",
    "            np.exp(output_array) / np.sum(np.exp(output_array), axis=1)[:, None]\n",
    "        )\n",
    "        # output_array = model(frames)\n",
    "        # end_p_time = datetime.now()\n",
    "        # print(\"Duration: {}\".format(end_p_time - start_p_time))\n",
    "        # result = model.run(None, {\"input\": frames.numpy()})\n",
    "        # output_array = result[0]\n",
    "        for frame_id in range(0, len(output_array)):\n",
    "            row_id = base_row_id + f\"_{(frame_id+1) * CFG.output_window_duration}\"\n",
    "            new_row_data = np.concatenate(([row_id], output_array[frame_id]))\n",
    "            new_rows.append(new_row_data)\n",
    "\n",
    "    pred_df = pd.DataFrame(new_rows, columns=pred_df.columns)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(\"Duration: {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in test_df[\"filepath\"]:\n",
    "#     base_row_id = path.split(\"/\")[-1].split(\".\")[0]\n",
    "#     data_loader = DataLoader(path)\n",
    "#     frames = data_loader.frames\n",
    "#     with torch.no_grad():\n",
    "#         output_array = model(frames)\n",
    "#         # output_array = torch.randn(49, 182)\n",
    "#         #     result = model.run(None, {\"input\": frames.numpy()})\n",
    "#         #     output_array = result[0]\n",
    "#         for frame_id in range(0, len(output_array)):\n",
    "#             row_id = base_row_id + f\"_{(frame_id+1) * CFG.output_window_duration}\"\n",
    "#             new_row_data = np.concatenate(([row_id], output_array[frame_id]))\n",
    "#             new_row = pd.DataFrame([new_row_data], columns=pred_df.columns)\n",
    "\n",
    "#             pred_df = pd.concat([pred_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     20\u001b[0m execution_times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m---> 21\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     24\u001b[0m execution_times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrames extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m, in \u001b[0;36mDataLoaderV2.forward\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     56\u001b[0m standardize_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m standardize_time\n\u001b[1;32m     58\u001b[0m get_frames_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 59\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m get_frames_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m get_frames_time\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# print(f\"Load Time: {load_time}\")\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(f\"Standardize Time: {standardize_time}\")\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(f\"Get Frames Time: {get_frames_time}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m, in \u001b[0;36mDataLoaderV2.get_frames\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     38\u001b[0m     frames_count,\n\u001b[1;32m     39\u001b[0m ):\n\u001b[1;32m     40\u001b[0m     window \u001b[38;5;241m=\u001b[39m waveform_with_padding[\n\u001b[1;32m     41\u001b[0m         :, i : i \u001b[38;5;241m+\u001b[39m CFG\u001b[38;5;241m.\u001b[39msample_rate \u001b[38;5;241m*\u001b[39m CFG\u001b[38;5;241m.\u001b[39minput_window_duration\n\u001b[1;32m     42\u001b[0m     ]\n\u001b[0;32m---> 43\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreparedWawe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     windows\u001b[38;5;241m.\u001b[39mappend(window)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(windows)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 127\u001b[0m, in \u001b[0;36mMonoToThreeChannel.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    118\u001b[0m chroma \u001b[38;5;241m=\u001b[39m generate_chroma_feature(\n\u001b[1;32m    119\u001b[0m     waveform,\n\u001b[1;32m    120\u001b[0m     sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_rate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     n_chroma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_chroma,\n\u001b[1;32m    124\u001b[0m )\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Resize Chroma to match Mel Spectrogram dimensions\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m chroma_resized \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmel_spectrogram_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# print(f\"Chroma Time: {time.time() - chroma_time}\")\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# stack_time = time.time()\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Stack to create a 3-channel image\u001b[39;00m\n\u001b[1;32m    134\u001b[0m final_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    135\u001b[0m     [mel_spectrogram_db, mfcc_resized, chroma_resized], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    136\u001b[0m )\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/functional.py:4065\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   4059\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m   4060\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001b[39;00m\n\u001b[1;32m   4061\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4062\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4063\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_upsample_linear_vec(\n\u001b[1;32m   4064\u001b[0m                 \u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 4065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_bilinear2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4067\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "new_rows = []\n",
    "# Initialize a dictionary to store execution times\n",
    "execution_times = {\n",
    "    \"DataLoader\": 0,\n",
    "    \"Frames extraction\": 0,\n",
    "    \"Output array generation\": 0,\n",
    "    \"Row ID generation\": 0,\n",
    "    \"New row data concatenation\": 0,\n",
    "    \"New row creation\": 0,\n",
    "    \"Dataframe concatenation\": 0,\n",
    "}\n",
    "data_loader = DataLoaderV2()\n",
    "for path in test_df[\"filepath\"]:\n",
    "    base_row_id = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    execution_times[\"DataLoader\"] += time.time() - start_time\n",
    "    frames = data_loader.forward(path)\n",
    "    start_time = time.time()\n",
    "\n",
    "    execution_times[\"Frames extraction\"] += time.time() - start_time\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        output_array = onnx_model.run(None, {\"input\": frames.numpy()})[0]\n",
    "        execution_times[\"Output array generation\"] += time.time() - start_time\n",
    "\n",
    "        for frame_id in range(0, len(output_array)):\n",
    "            start_time = time.time()\n",
    "            row_id = base_row_id + f\"_{(frame_id+1) * CFG.output_window_duration}\"\n",
    "            execution_times[\"Row ID generation\"] += time.time() - start_time\n",
    "\n",
    "            start_time = time.time()\n",
    "            new_row_data = np.concatenate(([row_id], output_array[frame_id]))\n",
    "            execution_times[\"New row data concatenation\"] += time.time() - start_time\n",
    "\n",
    "            # start_time = time.time()\n",
    "            # new_row = pd.DataFrame([new_row_data], columns=pred_df.columns)\n",
    "            # execution_times[\"New row creation\"] += time.time() - start_time\n",
    "\n",
    "            # start_time = time.time()\n",
    "            # # pred_df = pd.concat([pred_df, new_row], ignore_index=True)\n",
    "            # execution_times[\"Dataframe concatenation\"] += time.time() - start_time\n",
    "            new_rows.append(new_row_data)\n",
    "\n",
    "# Print the total execution time for each operation\n",
    "for operation, total_time in execution_times.items():\n",
    "    print(f\"{operation} total execution time: {total_time} seconds\")\n",
    "\n",
    "concat_start_time = time.time()\n",
    "# pred_df = pd.concat([pred_df] + new_rows, ignore_index=True)\n",
    "pred_df = pd.DataFrame(new_rows, columns=pred_df.columns)\n",
    "concat_time = time.time() - concat_start_time\n",
    "print(f\"Dataframe concatenation total execution time: {concat_time} seconds\")\n",
    "# Print the final total execution time\n",
    "print(f\"Final total execution time: {sum(execution_times.values())} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1384345978_5</td>\n",
       "      <td>0.005147201</td>\n",
       "      <td>0.0061734063</td>\n",
       "      <td>0.0048764125</td>\n",
       "      <td>0.005751291</td>\n",
       "      <td>0.0052085556</td>\n",
       "      <td>0.005743291</td>\n",
       "      <td>0.004999479</td>\n",
       "      <td>0.005302723</td>\n",
       "      <td>0.0052602133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004991829</td>\n",
       "      <td>0.0050446074</td>\n",
       "      <td>0.005801107</td>\n",
       "      <td>0.0053981678</td>\n",
       "      <td>0.00486379</td>\n",
       "      <td>0.006057547</td>\n",
       "      <td>0.0049511557</td>\n",
       "      <td>0.005269667</td>\n",
       "      <td>0.005465206</td>\n",
       "      <td>0.005681181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1384345978_10</td>\n",
       "      <td>0.005146629</td>\n",
       "      <td>0.0061731753</td>\n",
       "      <td>0.0048760525</td>\n",
       "      <td>0.0057515227</td>\n",
       "      <td>0.0052076178</td>\n",
       "      <td>0.0057427045</td>\n",
       "      <td>0.0049988586</td>\n",
       "      <td>0.005302563</td>\n",
       "      <td>0.0052604666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0049912524</td>\n",
       "      <td>0.00504488</td>\n",
       "      <td>0.0058009285</td>\n",
       "      <td>0.0053988607</td>\n",
       "      <td>0.004863322</td>\n",
       "      <td>0.0060578655</td>\n",
       "      <td>0.0049511665</td>\n",
       "      <td>0.0052697347</td>\n",
       "      <td>0.0054650446</td>\n",
       "      <td>0.005681448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1384345978_15</td>\n",
       "      <td>0.00514732</td>\n",
       "      <td>0.006172775</td>\n",
       "      <td>0.004876248</td>\n",
       "      <td>0.005751765</td>\n",
       "      <td>0.0052078534</td>\n",
       "      <td>0.005743118</td>\n",
       "      <td>0.004999144</td>\n",
       "      <td>0.005302401</td>\n",
       "      <td>0.005260132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0049919565</td>\n",
       "      <td>0.005044689</td>\n",
       "      <td>0.005800323</td>\n",
       "      <td>0.005399111</td>\n",
       "      <td>0.004864014</td>\n",
       "      <td>0.0060582147</td>\n",
       "      <td>0.0049505862</td>\n",
       "      <td>0.005269627</td>\n",
       "      <td>0.0054649385</td>\n",
       "      <td>0.005680998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1384345978_20</td>\n",
       "      <td>0.005146947</td>\n",
       "      <td>0.0061731027</td>\n",
       "      <td>0.004875316</td>\n",
       "      <td>0.0057510873</td>\n",
       "      <td>0.005207201</td>\n",
       "      <td>0.0057424707</td>\n",
       "      <td>0.0049989442</td>\n",
       "      <td>0.0053020185</td>\n",
       "      <td>0.0052599153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0049910657</td>\n",
       "      <td>0.00504326</td>\n",
       "      <td>0.005800944</td>\n",
       "      <td>0.005399625</td>\n",
       "      <td>0.0048632617</td>\n",
       "      <td>0.006058574</td>\n",
       "      <td>0.0049508465</td>\n",
       "      <td>0.005268942</td>\n",
       "      <td>0.005465236</td>\n",
       "      <td>0.0056815813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1384345978_25</td>\n",
       "      <td>0.005147329</td>\n",
       "      <td>0.0061728493</td>\n",
       "      <td>0.0048768343</td>\n",
       "      <td>0.0057515777</td>\n",
       "      <td>0.005207862</td>\n",
       "      <td>0.005743648</td>\n",
       "      <td>0.004999532</td>\n",
       "      <td>0.0053020595</td>\n",
       "      <td>0.0052602133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004991972</td>\n",
       "      <td>0.0050445623</td>\n",
       "      <td>0.005800219</td>\n",
       "      <td>0.005399083</td>\n",
       "      <td>0.0048635965</td>\n",
       "      <td>0.0060584596</td>\n",
       "      <td>0.004950595</td>\n",
       "      <td>0.0052698026</td>\n",
       "      <td>0.0054647317</td>\n",
       "      <td>0.0056813313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>236907488_220</td>\n",
       "      <td>0.0054165</td>\n",
       "      <td>0.0061859293</td>\n",
       "      <td>0.0050422684</td>\n",
       "      <td>0.0055292025</td>\n",
       "      <td>0.005502835</td>\n",
       "      <td>0.0058812676</td>\n",
       "      <td>0.005179063</td>\n",
       "      <td>0.005402188</td>\n",
       "      <td>0.005198712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0052447473</td>\n",
       "      <td>0.005131747</td>\n",
       "      <td>0.0055992454</td>\n",
       "      <td>0.0052675316</td>\n",
       "      <td>0.0050317743</td>\n",
       "      <td>0.0058826343</td>\n",
       "      <td>0.004956606</td>\n",
       "      <td>0.005279122</td>\n",
       "      <td>0.0056212125</td>\n",
       "      <td>0.0055916305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>236907488_225</td>\n",
       "      <td>0.0054206094</td>\n",
       "      <td>0.0061847353</td>\n",
       "      <td>0.0050450154</td>\n",
       "      <td>0.0055272398</td>\n",
       "      <td>0.0055061686</td>\n",
       "      <td>0.0058814613</td>\n",
       "      <td>0.0051838444</td>\n",
       "      <td>0.0054034395</td>\n",
       "      <td>0.0051970114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005247497</td>\n",
       "      <td>0.00513517</td>\n",
       "      <td>0.005599293</td>\n",
       "      <td>0.005266187</td>\n",
       "      <td>0.005035206</td>\n",
       "      <td>0.0058799773</td>\n",
       "      <td>0.0049571176</td>\n",
       "      <td>0.005279223</td>\n",
       "      <td>0.005623001</td>\n",
       "      <td>0.0055923103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>236907488_230</td>\n",
       "      <td>0.005421971</td>\n",
       "      <td>0.006184904</td>\n",
       "      <td>0.0050434456</td>\n",
       "      <td>0.0055252635</td>\n",
       "      <td>0.0055078436</td>\n",
       "      <td>0.0058809975</td>\n",
       "      <td>0.0051824027</td>\n",
       "      <td>0.0054036714</td>\n",
       "      <td>0.005195678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0052463524</td>\n",
       "      <td>0.005132748</td>\n",
       "      <td>0.0055999015</td>\n",
       "      <td>0.0052672755</td>\n",
       "      <td>0.0050358484</td>\n",
       "      <td>0.00587914</td>\n",
       "      <td>0.004958495</td>\n",
       "      <td>0.00527751</td>\n",
       "      <td>0.005624616</td>\n",
       "      <td>0.0055916086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>236907488_235</td>\n",
       "      <td>0.005424629</td>\n",
       "      <td>0.006184783</td>\n",
       "      <td>0.0050464226</td>\n",
       "      <td>0.005523612</td>\n",
       "      <td>0.005509389</td>\n",
       "      <td>0.005881282</td>\n",
       "      <td>0.005187987</td>\n",
       "      <td>0.005403959</td>\n",
       "      <td>0.005194869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0052500917</td>\n",
       "      <td>0.0051368065</td>\n",
       "      <td>0.0055993753</td>\n",
       "      <td>0.005265458</td>\n",
       "      <td>0.005038399</td>\n",
       "      <td>0.005878063</td>\n",
       "      <td>0.004957895</td>\n",
       "      <td>0.0052789547</td>\n",
       "      <td>0.005624978</td>\n",
       "      <td>0.0055921385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>236907488_240</td>\n",
       "      <td>0.0054218895</td>\n",
       "      <td>0.00618697</td>\n",
       "      <td>0.005045538</td>\n",
       "      <td>0.005524152</td>\n",
       "      <td>0.005506768</td>\n",
       "      <td>0.005880242</td>\n",
       "      <td>0.0051852874</td>\n",
       "      <td>0.005404382</td>\n",
       "      <td>0.00519604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00524894</td>\n",
       "      <td>0.0051346845</td>\n",
       "      <td>0.00559923</td>\n",
       "      <td>0.00526703</td>\n",
       "      <td>0.0050358903</td>\n",
       "      <td>0.0058819996</td>\n",
       "      <td>0.004957409</td>\n",
       "      <td>0.0052797487</td>\n",
       "      <td>0.005623184</td>\n",
       "      <td>0.005590686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4320 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             row_id        asbfly       ashdro1       ashpri1       ashwoo2  \\\n",
       "0      1384345978_5   0.005147201  0.0061734063  0.0048764125   0.005751291   \n",
       "1     1384345978_10   0.005146629  0.0061731753  0.0048760525  0.0057515227   \n",
       "2     1384345978_15    0.00514732   0.006172775   0.004876248   0.005751765   \n",
       "3     1384345978_20   0.005146947  0.0061731027   0.004875316  0.0057510873   \n",
       "4     1384345978_25   0.005147329  0.0061728493  0.0048768343  0.0057515777   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "4315  236907488_220     0.0054165  0.0061859293  0.0050422684  0.0055292025   \n",
       "4316  236907488_225  0.0054206094  0.0061847353  0.0050450154  0.0055272398   \n",
       "4317  236907488_230   0.005421971   0.006184904  0.0050434456  0.0055252635   \n",
       "4318  236907488_235   0.005424629   0.006184783  0.0050464226   0.005523612   \n",
       "4319  236907488_240  0.0054218895    0.00618697   0.005045538   0.005524152   \n",
       "\n",
       "           asikoe2       asiope1       aspfly1       aspswi1       barfly1  \\\n",
       "0     0.0052085556   0.005743291   0.004999479   0.005302723  0.0052602133   \n",
       "1     0.0052076178  0.0057427045  0.0049988586   0.005302563  0.0052604666   \n",
       "2     0.0052078534   0.005743118   0.004999144   0.005302401   0.005260132   \n",
       "3      0.005207201  0.0057424707  0.0049989442  0.0053020185  0.0052599153   \n",
       "4      0.005207862   0.005743648   0.004999532  0.0053020595  0.0052602133   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4315   0.005502835  0.0058812676   0.005179063   0.005402188   0.005198712   \n",
       "4316  0.0055061686  0.0058814613  0.0051838444  0.0054034395  0.0051970114   \n",
       "4317  0.0055078436  0.0058809975  0.0051824027  0.0054036714   0.005195678   \n",
       "4318   0.005509389   0.005881282   0.005187987   0.005403959   0.005194869   \n",
       "4319   0.005506768   0.005880242  0.0051852874   0.005404382    0.00519604   \n",
       "\n",
       "      ...       whbwoo2       whcbar1       whiter2        whrmun  \\\n",
       "0     ...   0.004991829  0.0050446074   0.005801107  0.0053981678   \n",
       "1     ...  0.0049912524    0.00504488  0.0058009285  0.0053988607   \n",
       "2     ...  0.0049919565   0.005044689   0.005800323   0.005399111   \n",
       "3     ...  0.0049910657    0.00504326   0.005800944   0.005399625   \n",
       "4     ...   0.004991972  0.0050445623   0.005800219   0.005399083   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "4315  ...  0.0052447473   0.005131747  0.0055992454  0.0052675316   \n",
       "4316  ...   0.005247497    0.00513517   0.005599293   0.005266187   \n",
       "4317  ...  0.0052463524   0.005132748  0.0055999015  0.0052672755   \n",
       "4318  ...  0.0052500917  0.0051368065  0.0055993753   0.005265458   \n",
       "4319  ...    0.00524894  0.0051346845    0.00559923    0.00526703   \n",
       "\n",
       "           whtkin2        woosan       wynlau1       yebbab1       yebbul3  \\\n",
       "0       0.00486379   0.006057547  0.0049511557   0.005269667   0.005465206   \n",
       "1      0.004863322  0.0060578655  0.0049511665  0.0052697347  0.0054650446   \n",
       "2      0.004864014  0.0060582147  0.0049505862   0.005269627  0.0054649385   \n",
       "3     0.0048632617   0.006058574  0.0049508465   0.005268942   0.005465236   \n",
       "4     0.0048635965  0.0060584596   0.004950595  0.0052698026  0.0054647317   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4315  0.0050317743  0.0058826343   0.004956606   0.005279122  0.0056212125   \n",
       "4316   0.005035206  0.0058799773  0.0049571176   0.005279223   0.005623001   \n",
       "4317  0.0050358484    0.00587914   0.004958495    0.00527751   0.005624616   \n",
       "4318   0.005038399   0.005878063   0.004957895  0.0052789547   0.005624978   \n",
       "4319  0.0050358903  0.0058819996   0.004957409  0.0052797487   0.005623184   \n",
       "\n",
       "           zitcis1  \n",
       "0      0.005681181  \n",
       "1      0.005681448  \n",
       "2      0.005680998  \n",
       "3     0.0056815813  \n",
       "4     0.0056813313  \n",
       "...            ...  \n",
       "4315  0.0055916305  \n",
       "4316  0.0055923103  \n",
       "4317  0.0055916086  \n",
       "4318  0.0055921385  \n",
       "4319   0.005590686  \n",
       "\n",
       "[4320 rows x 183 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first row without row_id and convert to float\n",
    "first_row = pred_df.iloc[0, 1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11336/1387125839.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  torch.nn.Softmax()(torch.tensor([first_row]))\n",
      "/home/lex/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0033, 0.0052, 0.0013, 0.0078, 0.0024, 0.0014, 0.0011, 0.0077, 0.0012,\n",
       "         0.0180, 0.0034, 0.0086, 0.0089, 0.0132, 0.0044, 0.0036, 0.0064, 0.0049,\n",
       "         0.0024, 0.0019, 0.0058, 0.0014, 0.0016, 0.0039, 0.0046, 0.0114, 0.0035,\n",
       "         0.0035, 0.0035, 0.0043, 0.0016, 0.0025, 0.0036, 0.0055, 0.0240, 0.0024,\n",
       "         0.0134, 0.0055, 0.0020, 0.0024, 0.0071, 0.0028, 0.0011, 0.0196, 0.0081,\n",
       "         0.0009, 0.0028, 0.0012, 0.0012, 0.0061, 0.0039, 0.0061, 0.0060, 0.0055,\n",
       "         0.0164, 0.0256, 0.0003, 0.0029, 0.0050, 0.0159, 0.0103, 0.0010, 0.0068,\n",
       "         0.0030, 0.0122, 0.0017, 0.0034, 0.0043, 0.0008, 0.0013, 0.0008, 0.0145,\n",
       "         0.0009, 0.0034, 0.0024, 0.0003, 0.0164, 0.0023, 0.0136, 0.0012, 0.0020,\n",
       "         0.0089, 0.0022, 0.0091, 0.0075, 0.0011, 0.0166, 0.0014, 0.0042, 0.0050,\n",
       "         0.0007, 0.0025, 0.0037, 0.0301, 0.0028, 0.0013, 0.0033, 0.0023, 0.0022,\n",
       "         0.0126, 0.0041, 0.0030, 0.0088, 0.0032, 0.0013, 0.0037, 0.0008, 0.0044,\n",
       "         0.0152, 0.0007, 0.0043, 0.0014, 0.0082, 0.0017, 0.0047, 0.0026, 0.0095,\n",
       "         0.0015, 0.0070, 0.0054, 0.0008, 0.0048, 0.0007, 0.0032, 0.0058, 0.0026,\n",
       "         0.0035, 0.0032, 0.0011, 0.0026, 0.0093, 0.0100, 0.0008, 0.0016, 0.0104,\n",
       "         0.0039, 0.0035, 0.0122, 0.0032, 0.0016, 0.0011, 0.0075, 0.0078, 0.0021,\n",
       "         0.0012, 0.0248, 0.0103, 0.0043, 0.0007, 0.0439, 0.0084, 0.0016, 0.0077,\n",
       "         0.0025, 0.0017, 0.0054, 0.0004, 0.0006, 0.0055, 0.0030, 0.0023, 0.0141,\n",
       "         0.0053, 0.0013, 0.0084, 0.0018, 0.0059, 0.0030, 0.0166, 0.0060, 0.0010,\n",
       "         0.0011, 0.0014, 0.0017, 0.0006, 0.0126, 0.0018, 0.0196, 0.0012, 0.0011,\n",
       "         0.0024, 0.0018]], dtype=torch.float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax()(torch.tensor([first_row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3213e-02, 2.6539e-01, 7.2140e-01],\n",
       "        [2.6944e-07, 1.1920e-01, 8.8080e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(dim=1)(torch.tensor([[-1.0, 2.0, 3.0], [-6.0, 7.0, 9.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lex/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3213e-02, 2.6539e-01, 7.2140e-01],\n",
       "        [2.6944e-07, 1.1920e-01, 8.8080e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax()(torch.tensor([[-1.0, 2.0, 3.0], [-6.0, 7.0, 9.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9933, 0.0067, 0.0025],\n",
       "        [0.0067, 0.9933, 0.9975]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(dim=0)(torch.tensor([[-1.0, 2.0, 3.0], [-6.0, 7.0, 9.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_df = pd.read_csv(\"keras_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(keras_df) == len(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that row_ids are the same\n",
    "assert (keras_df.row_id == pred_df.row_id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that columns are the same\n",
    "assert (keras_df.columns == pred_df.columns).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
